# êµ°ì§‘í™” (Clustering)

- ë¹„ì§€ë„ í•™ìŠµ
- ë°ì´í„°ì˜ ì„±ì§ˆë¡œ ë¶€í„° ìµœì ìœ¼ë¡œ ë¶„í• í•˜ê³  ë ˆì´ë¸”ì„ êµ¬í•¨
- í™œìš© ë¶„ì•¼
  - ì‹œì¥ ë¶„í• 
  - ì§€ë„ì—ì„œ ê°€ê¹Œìš´ ì§€ì ì„ ë³‘í•¨
  - ì˜ìƒ ì••ì¶•
  - ìë£Œì— ìƒˆ ë ˆì´ë¸” ë¶€ì—¬
  - ì´ìƒí–‰ë™ ê°ì§€
- ë°©ë²•ë¡ 
  - K-means clustering, DBSCAN, ect



---

## K- í‰ê·  êµ°ì§‘í™”

- ë ˆì´ë¸”ì´ ì—†ëŠ” ë‹¤ì°¨ì› ë°ì´í„° ì„¸íŠ¸ ë‚´ì— ì‚¬ì „ ì •ì˜ëœ êµ°ì§‘ì˜ ê°œìˆ˜ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ë²• 
-  ìµœì ì˜ êµ°ì§‘í™” 
  - ''êµ°ì§‘ì˜ ì¤‘ì•™' ì€ í•´ë‹¹ êµ°ì§‘ì— ì†í•˜ëŠ” ëª¨ë“  ì ì˜ ì‚°ìˆ  í‰ê· 
  - ê° ì ì€ ë‹¤ë¥¸ êµ°ì§‘ì˜ ì¤‘ì•™ë³´ë‹¤ ìì‹ ì´ ì†í•œ êµ°ì§‘ì˜ ì¤‘ì•™ì— ë” ê°€ê¹ë‹¤.

```python
%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
import numpy as np
```

```python
# 4ê°œ ì˜ì—­ì˜ 2ì°¨ì› ìë£Œì˜ ìƒì„±
from sklearn.datasets import make_blobs
# y_ture ëŠ” clusterì˜ num. XëŠ” dotì˜ ì¢Œí‘œê°’. ë”°ë¼ì„œ ì•„ë˜ì—ì„œëŠ” ì‚¬ì‹¤ í•„ìš”ì—†ìŒ
X, y_true = make_blobs(n_samples=300, centers=4, 
                       cluster_std = 0.60, random_state = 0)

plt.scatter(X[:,0], X[:,1], s=50)

```

![image-20220211105521692](image.assets/image-20220211105521692.png)

```python
# k-means clustering
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters = 4)
y_kmeans = kmeans.fit_predict(X)
print(y_kmeans)
'''
[2 3 1 3 2 2 0 1 3 3 0 3 1 3 2 1 1 2 0 0 2 2 1 0 0 1 2 1 0 1 3 3 1 3 3 3 3
 3 0 2 1 0 1 1 0 0 3 0 3 2 0 2 3 2 2 0 3 0 3 2 3 1 3 0 0 0 3 2 3 0 1 0 3 0
 0 3 0 1 2 3 2 1 2 2 3 1 2 1 3 3 1 2 3 0 0 1 2 2 1 0 3 2 3 2 1 2 2 1 3 1 0
 0 2 3 2 1 3 2 2 1 0 2 0 2 2 2 2 0 2 0 3 0 0 2 3 0 0 3 1 3 3 0 1 0 1 0 3 1
 3 3 3 1 3 1 2 0 3 0 2 1 3 1 1 2 1 0 0 1 2 1 1 3 2 1 0 3 2 2 1 0 2 1 0 0 1
 1 1 1 2 3 1 0 1 1 0 0 0 1 0 3 1 0 2 0 1 3 0 3 1 3 1 0 1 1 3 0 0 2 2 1 3 2
 2 0 2 0 1 3 3 1 1 3 1 2 0 1 2 0 3 0 2 1 2 3 3 3 3 0 0 3 1 0 2 1 0 0 0 2 2
 3 1 1 0 2 3 0 1 3 1 2 2 0 0 1 2 2 2 1 3 3 2 2 1 2 2 2 3 0 3 1 2 2 3 3 3 2
 2 1 3 0]
'''
```

```python
# ê·¸ë£¹ë³„ë¡œ ìƒ‰ê¹”ì„ ë‹¬ë¦¬ í‘œí˜„í•˜ê¸°, êµ°ì§‘ ì¤‘ì•™í‘œì‹œ
plt.scatter(X[:,0], X[:,1], c=y_kmeans, s=50, cmap = 'viridis')
centers = kmeans.cluster_centers_
plt.scatter(centers[:,0], centers[:,1], c='k', s=200, alpha=0.5)
```

![image-20220211105558262](image.assets/image-20220211105558262.png)

#### K-means êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜

- ê¸°ëŒ€ê°’-ìµœëŒ€í™”(E-M) ì•Œê³ ë¦¬ì¦˜

  â‘  ì¼ë¶€ êµ°ì§‘ ì¤‘ì‹¬ì„ ì¶”ì¸¡í•œë‹¤.(ë‚œìˆ˜ ì´ˆê¸°ê°’) 

  â‘¡ ìˆ˜ë ´ë  ë•Œê¹Œì§€ ë‹¤ìŒì„ ë°˜ë³µí•œë‹¤. 

  -  E-ë‹¨ê³„(ê¸°ëŒ“ê°’ ë‹¨ê³„): ì ì„ ê°€ì¥ ê°€ê¹Œìš´ êµ°ì§‘ ì¤‘ì‹¬ì— í• ë‹¹í•œë‹¤. 
  - M-ë‹¨ê³„(ìµœëŒ€í™” ë‹¨ê³„): êµ°ì§‘ ì¤‘ì‹¬ì„ í‰ê· ê°’ìœ¼ë¡œ ì„¤ì •í•œë‹¤. (êµ°ì§‘ì— ì†í•œ ë°ì´í„°ì˜ ì‚°ìˆ  í‰ê· )

#### ê¸°ëŒ€ê°’-ìµœëŒ€í™”(E-M) ì•Œê³ ë¦¬ì¦˜ ê´€ë ¨ ì£¼ì˜ì‚¬í•­

- ìµœì´ˆì˜ êµ°ì§‘ ì¤‘ì‹¬ì„ ë‚œìˆ˜ ì´ˆê¸°ê°’ìœ¼ë¡œ ì •í•˜ê¸° ë•Œë¬¸ì— ìµœì í™”ëœ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í•˜ëŠ” ê²½ìš°ë„ ìˆë‹¤. 
- êµ°ì§‘ì˜ ê°œìˆ˜ê°€ ì‚¬ì „ì— ì •í•´ì ¸ì•¼ í•œë‹¤. 
- **K-í‰ê·  êµ°ì§‘ì€ ì„ í˜• êµ°ì§‘ ê²½ê³„ë¡œ í•œì •ëœë‹¤.** (ì¹˜ëª…ì  ë‹¨ì ) 
- K-í‰ê·  ê· ì§‘ì€ í‘œë³¸ ìˆ˜ê°€ ë§ì•„ì§€ë©´ ëŠë ¤ì§„ë‹¤ 
  - ì•Œê³ ë¦¬ì¦˜ì„ ë°˜ë³µí•  ë•Œë§ˆë‹¤ ë°ì´í„°ì„¸íŠ¸ì˜ ëª¨ë“  ì ì— ì ‘ê·¼í•´ì•¼ í•˜ë¯€ë¡œ

```python
# ë¹„ì„ í˜• ê²½ê³„ë¥¼ ê°€ì§€ëŠ” ìë£Œì˜ ê²½ìš°

from sklearn.datasets import make_moons
X, y = make_moons(200, noise=0.05, random_state = 0)
labels = KMeans(2, random_state = 0).fit_predict(X)
plt.scatter(X[:,0], X[:,1], c=labels, s=50, cmap='viridis')
```

![image-20220211105613940](image.assets/image-20220211105613940.png)

```python
# í•„ê¸°ì²´ ìˆ«ì ì¸ì‹ì— ì ìš©
from sklearn.datasets import load_digits
digits = load_digits()
digits.data.shape
'''
(1797, 64)
'''
```

```python
# k-meansa clustering
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters= 10, random_state= 0)
clusters = kmeans.fit_predict(digits.data)
kmeans.cluster_centers_.shape
'''
(10, 64)
'''
```

```python
# 64ì°¨ì›ì˜ êµ°ì§‘ 10ê°œ
fig, ax = plt.subplots(2,5, figsize=(8,3)) # axëŠ” ì¶•
centers = kmeans.cluster_centers_.reshape(10,8,8)
for axi, center in zip(ax.flat, centers):
  axi.set(xticks=[], yticks=[])
  axi.imshow(center, interpolation = 'nearest', cmap=plt.cm.binary)
```

![image-20220211105700173](image.assets/image-20220211105700173.png)



---

## DBSCAN

- Density Based Spatial Clustering of Application with Noise
- ì„ í˜• êµ°ì§‘ ê²½ê³„ë¡œ í•œì •ë˜ëŠ” K-í‰ê·  êµ°ì§‘ì˜ ë‹¨ì ì„ ë³´ì™„

#### íŠ¹ì§•

- ë…¸ì´ì¦ˆì— ê°•í•œ êµ°ì§‘ ëª¨ë¸ 
- ë°€ë„ìˆê²Œ ì—°ê²°ë˜ì–´ ìˆëŠ” ë°ì´í„° ì§‘í•©ì„ ë™ì¼í•œ í´ëŸ¬ìŠ¤í„°ë¡œ ê²°ì •í•¨ 
- ì¼ì •í•œ ë°€ë„ë¥¼ ê°€ì§€ëŠ” ë°ì´í„° ë¬´ë¦¬ê°€ ì²´ì¸ì²˜ëŸ¼ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©´ ê±°ë¦¬ì˜ ê°œë…ê³¼ ê´€ê³„ì—†ì´ ê°™ì€ í´ëŸ¬ìŠ¤í„°ë¡œ íŒë‹¨í•¨

- clusterì˜ ê°œìˆ˜ê°€ ì •í•´ì ¸ì‡ì§€ ì•ŠìŒ

#### DBSCAN ìš©ì–´

X : í•™ìŠµ ë°ì´í„° ì „ì²´ ì§‘í•© 

ğœ€ âˆ¶ ë°€ë„ì¸¡ì • ë°˜ì§€ë¦„ 

ğ‘€ğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  : ë°˜ì§€ë¦„ ğœ€ ì´ë‚´ì— ìˆëŠ” ìµœì†Œ ë°ì´í„° ê°œìˆ˜ 

N(x) : ë°ì´í„° xì˜ ë°˜ì§€ë¦„ ğœ€ ë‚´ì— ìˆëŠ” ì´ì›ƒ ë°ì´í„°(neighbor) ìˆ˜ 

{x} : ë°ì´í„° xì˜ ë°˜ì§€ë¦„ ğœ€ ë‚´ì— ìˆëŠ” ì´ì›ƒ ë°ì´í„°

- x is ğ‘¥ğ‘ğ‘œğ‘Ÿğ‘’ if N(x) â‰¥ ğ‘€ğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  âˆ€ğ‘¥âˆˆğ‘‹ 
- x is ğ‘¥ğ‘ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ if xâˆˆ {ğ‘¥ğ‘ğ‘œğ‘Ÿğ‘’ } ì´ê³  N(x) < ğ‘€ğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  âˆ€ğ‘¥âˆˆğ‘‹ 
- x is ğ‘¥ğ‘›ğ‘œğ‘–ğ‘ ğ‘’ if xâˆ‰ {ğ‘¥ğ‘ğ‘œğ‘Ÿğ‘’ } ì´ê³  N x < ğ‘€ğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  âˆ€ğ‘¥âˆˆğ‘‹ 

#### DBSCAN ì•Œê³ ë¦¬ì¦˜

1. ë°€ë„ ë°˜ì§€ë¦„ ğœ€ ë°˜ê²½ ë‚´ ìµœì†Œ ë°ì´í„° ê°œìˆ˜(MinPts) ì •ì˜, C=0 

2. ëª¨ë“  ë°ì´í„° x âˆˆXì— ëŒ€í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰ 

   2-1) xì— ì²˜ìŒ ë°©ë¬¸í•˜ë©´ ë°©ë¬¸í–ˆë‹¤ê³  í‘œì‹œ 

   2-2) ë§Œì•½ N(x) < MinPts ì´ë©´ 

   â€‹	â‘  xëŠ” Noise, C=C+1 

   â€‹	â‘¡ 2ë‹¨ê³„ë¡œ ëŒì•„ê°€ ë‹¤ë¥¸ ë°ì´í„°ë¡œ ë‹¤ì‹œ ì‹œì‘ (ì½”ì–´ê°€ ì—†ìœ¼ë©´ 

   2-3) ë§Œì•½ N(x) > MinPts ì´ë©´ 

   â€‹	â‘  xëŠ” ì½”ì–´ 

   â€‹	â‘¡ xê°€ ì•„ì§ ì†Œì† í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìœ¼ë©´ C í• ë‹¹ 

   â€‹	â‘¢ xì˜ ë°€ë„ ë°˜ì§€ë¦„ì— ì†í•´ìˆëŠ” ëª¨ë“  ì ë“¤ì— ëŒ€í•´ 2ë‹¨ê³„ ë°˜ë³µ

- êµ°ì§‘í™”ì˜ ê³¼ì •ì€ ì½”ì–´->ì½”ì–´->ì½”ì–´-> â€¦->ê²½ê³„ ë°©í–¥



#### DBSCAN

```python
from sklearn.datasets import make_moons
X, y = make_moons(200, noise=0.05, random_state = 0)
```

```python
from sklearn.cluster import DBSCAN
D_labels = DBSCAN(eps=0.3, min_samples= 15).fit_predict(X)
plt.scatter(X[:,0], X[:,1], c=D_labels, s=50, cmap='viridis')
```

![image-20220211112706300](image.assets/image-20220211112706300.png)

##### ì¥ì 

- ë„ë„› ëª¨ì–‘ì´ë‚˜ ë°˜ë‹¬ ëª¨ì–‘ì˜ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ êµ°ì§‘ ê°€ëŠ¥

![image-20220211112751983](image.assets/image-20220211112751983.png)

##### ë‹¨ì 

- ë°€ë„ ë°˜ì§€ë¦„ ë° ìµœì†Œ ì´ì›ƒ ìˆ˜ê°€ ë¬¸ì œì˜ íŠ¹ì„±ì— ë”°ë¼ ë¯¼ê°í•˜ê²Œ ì‘ìš©í•¨

![image-20220211112827780](image.assets/image-20220211112827780.png)

---



## ë¹„ì§€ë„ í•™ìŠµ: ì£¼ì„±ë¶„ ë¶„ì„ (PCA)

- PCA(Principal Component Analysis)

  - ì£¼ì„±ë¶„ ì •ë³´ë¥¼ ë²¡í„°ì™€ ê¸¸ì´ë¡œ ë¶„ì„ 

  - í™œìš© ë¶„ì•¼ 

    â‘  ì£¼ì„±ë¶„ ë¶„ì„: 

    - ë°ì´í„°ì˜ ì£¼ì¶•(principal axes)ì˜ ëª©ë¡ì„ êµ¬í•˜ê³ , ê·¸ ì¶•ì„ ì‚¬ìš©í•´ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì„¤ëª… 

    - íŠ¹ì§• ì¶”ì¶œ 

    â‘¡ ì°¨ì› ì¶•ì†Œ: 
    
    -  ë°ì´í„°ì˜ ë¶„ì‚° ì •ë³´ë¥¼ ê°€ì¥ ë§ì´ í¬í•¨í•˜ëŠ” ì£¼ì¶•ìœ¼ë¡œ ì°¨ì› ì¶•ì†Œ

#### 1. ì£¼ì„±ë¶„ ë¶„ì„

```python
#PCA ë¥¼ ìœ„í•œ ìë£Œ ì¤€ë¹„
rng = np.random.RandomState(1)
X = np.dot(rng.rand(2,2), rng.randn(2, 200)).T
plt.scatter(X[:,0], X[:,1])
plt.axis('equal')
```

![image-20220211113222822](image.assets/image-20220211113222822.png)

- ì„±ë¶„(component): ë²¡í„°ì˜ ë°©í–¥
  - ë¶„ì‚°ì´ í° ìˆœì„œë¡œ PC ì¶•ì´ ì°¨ë¡€ë¡œ ìƒê¹€. ì˜ˆ) component 1 = PC1 , component 2 = PC2
  - PC ê¸°ì¤€ìœ¼ë¡œ ì¶• ë³€ê²½í•˜ì—¬ ìƒˆë¡œìš´ ì¢Œí‘œê°€ ìƒê¹€ 

- ì„¤ëª… ë¶„ì‚°(explained variance): í•´ë‹¹ ë²¡í„°ì˜ ì œê³± ê¸¸ì´

```python
from sklearn.decomposition import PCA
mypca = PCA(n_components = 2) 
mypca.fit(X)
```

```python
print(mypca.components_)
'''
[[-0.94446029 -0.32862557]  # component1 ì˜ ì¢Œí‘œ
 [-0.32862557  0.94446029]] # component 2 ì˜ ì¢Œí‘œ
'''
```

```python
print(mypca.explained_variance_)
'''
[0.7625315 0.0184779] # component1ê¹Œì§€ì˜ ê±°ë¦¬, component2ê¹Œì§€ì˜ ê±°ë¦¬
'''
```

- ì´ ë‘ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ PCì¶•ì´ ìƒê¹€



#### ì¶• ë§Œë“¤ê¸° í•¨ìˆ˜ 

```python
def draw_vector(V0, V1, ax=None):
    ax = ax or plt.gca() # gca()ëŠ” í˜„ì¬ Axes ê°ì²´ë¥¼ ë°˜í™˜í•œë‹¤.(get current axes)
    arrowprops = dict(color = 'r',
                     arrowstyle='simple',
                     linewidth=2,
                     shrinkA=0,
                     shrinkB=0)
    ax.annotate('', v1, v0, arrowprops=arrowprops)
    
# data plotting
plt.scatter(X[:,0], X[:,1], alpha=0.2)
for length, vector in zip(mypca.explained_variance_, mypca.components_):
    v = vector * 3 * np.sqrt(length)
    draw_vector(mypca.mean_, mypca.mean_ + v)
    
plt.axis('equal')
```

![image-20220211135333761](image.assets/image-20220211135333761.png)

#### ì°¨ì›ì¶•ì†Œì— ì‘ìš©

- ê°€ì¥ ì‘ì€ ì£¼ì„±ë¶„ ì¤‘ í•˜ë‚˜ë¥¼ ì‚­ì œí•´ ìµœëŒ€ ë°ì´í„° ë¶„ì‚°ì„ ë³´ì¡´í•˜ëŠ” ë” ì‘ì€ ì°¨ì›ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì‚¬ì˜í•¨
  - ê°€ì¥ ì‘ì€ ì£¼ì„±ë¶„ = ë¶„ì‚°ì´ ì œì¼ ì ì€ PC ì œì™¸í•˜ì—¬ ì°¨ì›ì„ ì¶•ì†Œí•¨ = ì˜¤ì°¨ë¥¼ ìµœì†Œí™” 

```python
dimpca = PCA(n_components=1)
dimpca.fit(X)
X_pca = dimpca.transform(X)
print('original shape: ', X.shape)
print('transformed shape: ', X_pca.shape)
'''
original shape:  (200, 2)
transformed shape:  (200, 1)
'''
```



- ìë£Œ ì¶œë ¥

```python
# ì—­ë³€í™˜
X_new = dimpca.inverse_transform(X_pca)
plt.scatter(X[:,0], X[:,1], alpha = 0.2)
plt.scatter(X_new[:,0], X_new[:,1], alpha = 0.8)
plt.axis('equal')
```

![image-20220211140935404](image.assets/image-20220211140935404.png)



#### 2. íŠ¹ì§• ì¶”ì¶œ: ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ

```python
# ê³ ìœ  ì–¼êµ´ ì„±ë¶„ ì°¾ê¸°
from sklearn.datasets import fetch_lfw_people
faces = fetch_lfw_people(min_faces_per_person=60)
print(faces.target_names)
print(faces.images.shape)
'''
['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'
 'Gerhard Schroeder' 'Hugo Chavez' 'Junichiro Koizumi' 'Tony Blair']
(1348, 62, 47)
'''
```

```python
from sklearn.decomposition import PCA
face_pca = PCA(150)
face_pca.fit(faces.data)
'''
PCA(n_components=150)
'''
```

```python
fig, axes = plt.subplots(3,8, figsize=(9,4),
                        subplot_kw = {'xticks': [], 'yticks': []},
                        gridspec_kw=dict(hspace=0.1, wspace=0.1))

for i, ax in enumerate(axes.flat):
    ax.imshow(face_pca.components_[i].reshape(62,47), cmap='bone')
```

![image-20220211141719035](image.assets/image-20220211141719035.png)



## ì„±ëŠ¥í‰ê°€

#### ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€ ì¢…ë¥˜ 

- TP(True Positive): ì‹¤ì œ ì–‘ì„±ì¸ë°, ê²€ì‚¬ ê²°ê³¼ ì–‘ì„± 
- TN(True Negative): ì‹¤ì œëŠ” ìŒì„±ì¸ë°, ê²€ì‚¬ ê²°ê³¼ ìŒì„±
- FP(False Positive): ì‹¤ì œëŠ” ìŒì„±ì¸ë° ê²€ì‚¬ê²°ê³¼ëŠ” ì–‘ì„±(ê±°ì§“ ì–‘ì„±)
- FN(False Negative): ì‹¤ì œëŠ” ì–‘ì„±ì¸ë°, ê²€ì‚¬ê²°ê³¼ëŠ” ìŒì„±(ê±°ì§“ ìŒì„±)

|           | ì‹¤ì œ ì–‘ì„± | ì‹¤ì œ ìŒì„± |
| :-------: | :-------: | :-------: |
| ê²€ì‚¬ ì–‘ì„± |    TP     |    FP     |
| ê²€ì‚¬ ìŒì„± |    FN     |    TN     |

| ê²°ê³¼ì˜ T or F \ ê²€ì‚¬ê²°ê³¼ | ì–‘ì„± | ìŒì„± |
| :----------------------: | :--: | :--: |
|           True           |  TP  |  TN  |
|          False           |  FP  |  FN  |

#### ì„±ëŠ¥ 

- ì •í™•ë„(accuracy) = (ğ‘‡ğ‘ƒ+ğ‘‡ğ‘) / (ğ‘‡ğ‘ƒ+ğ‘‡ğ‘+ğ¹ğ‘ƒ+ğ¹ğ‘)
- ì •ë°€ë„(precision) = ğ‘‡ğ‘ƒ / (ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ)
- ì¬í˜„ìœ¨(recall) = ğ‘‡ğ‘ƒ / (ğ‘‡ğ‘ƒ+ğ¹ğ‘) 
- ë¯¼ê°ë„(Sensitivity) = ğ‘‡ğ‘ƒ / (ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ) 
- íŠ¹ì´ë„(Specificity) = ğ‘‡ğ‘ / (ğ‘‡ğ‘+ğ¹ğ‘ƒ)

